{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "DWEi1xw6rXQH"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Input\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pymongo\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_blobs\n",
    "import sklearn as skl\n",
    "import tensorflow as tf\n",
    "from api_keys import mongo_username, mongo_password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "774E4NNNrgZr"
   },
   "outputs": [],
   "source": [
    "# Create connection string\n",
    "mongo_connection_string = f'mongodb+srv://{mongo_username}:{mongo_password}@cluster0.9gjuly6.mongodb.net/'\n",
    "\n",
    "# Connect to MongoDB\n",
    "mongo_client = pymongo.MongoClient(mongo_connection_string)\n",
    "\n",
    "# Create DB\n",
    "mongo_db = mongo_client.properties\n",
    "\n",
    "# Insert data into separate collections\n",
    "weather_collection = mongo_db.weather_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lU2t5aOfrpGH"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "0i6tubaErriF"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': ObjectId('65e88f0bf11610bf95cba113'),\n",
       " 'id': '6155PD4.1990.4.20',\n",
       " 'heating_degree_days': 6.5,\n",
       " 'min_temperature': 7.0,\n",
       " 'local_date': datetime.datetime(1990, 4, 20, 0, 0),\n",
       " 'station_name': 'OAKVILLE GERARD',\n",
       " 'cooling_degree_days': 0.0,\n",
       " 'local_month': 4,\n",
       " 'local_day': 20,\n",
       " 'local_year': 1990,\n",
       " 'total_precipitation': 9.0,\n",
       " 'snow_on_ground': 0.0,\n",
       " 'mean_temperature': 11.5,\n",
       " 'total_snow': 0.0,\n",
       " 'total_rain': 9.0,\n",
       " 'max_temperature': 16.0}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_document = weather_collection.find_one()\n",
    "\n",
    "sample_document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_cursor = weather_collection.find()\n",
    "df = pd.DataFrame(list(all_data_cursor))\n",
    "data = df[['local_date', 'max_temperature']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['heating_degree_days', 'min_temperature', 'local_date', 'station_name', 'cooling_degree_days', 'local_month', 'local_day', 'local_year', 'total_precipitation', 'snow_on_ground', 'mean_temperature', 'total_snow', 'total_rain']\n",
    "\n",
    "# Drop specified columns from the DataFrame\n",
    "df_cleaned = df.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "ufm9pqsDryOZ"
   },
   "outputs": [],
   "source": [
    "data.sort_values('local_date', inplace=True)\n",
    "data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "19gN1lUgr22b"
   },
   "outputs": [],
   "source": [
    "n_steps = 365\n",
    "\n",
    "def prepare_lstm_data(data, n_steps):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - n_steps):\n",
    "        end_ix = i + n_steps\n",
    "        seq_x = data['max_temperature'].values[i:end_ix]\n",
    "        seq_y = data['max_temperature'].values[end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "Qb0mrd07r4WR"
   },
   "outputs": [],
   "source": [
    "X, y = prepare_lstm_data(data, n_steps)\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "y_scaled = scaler.fit_transform(y.reshape(-1, 1)).flatten()\n",
    "\n",
    "split_ratio = 0.8  # 80% training, 20% validation\n",
    "split_idx = int(len(X_scaled) * split_ratio)\n",
    "\n",
    "# Assign X_train and y_train after scaling\n",
    "X_train, X_valid = X_scaled[:split_idx], X_scaled[split_idx:]\n",
    "y_train, y_valid = y_scaled[:split_idx], y_scaled[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (7280, 365), y_train shape: (7280, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "h9L1Zsqyr61Y"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\qwert\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Build LSTM model\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(30, 1)))  # Adjust input_shape based on your data\n",
    "model.add(Dense(1))  # Output layer with single neuron for regression\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "1U2jbO0Vr8Zv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 69ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/10\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 67ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/10\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 68ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/10\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 66ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/10\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 65ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/10\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 64ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/10\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 65ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/10\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 65ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/10\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 66ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/10\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 64ms/step - loss: nan - val_loss: nan\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - loss: nan\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable float object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m loss, accuracy \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_test, y_test)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(loss, accuracy)\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot unpack non-iterable float object"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(loss, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bTRo9TdZr_0x"
   },
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "forecast_steps = len(X_test)\n",
    "forecast = model.predict(X_test)\n",
    "\n",
    "# Inverse transform the predictions\n",
    "forecast = scaler.inverse_transform(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dywAxy1IsALr"
   },
   "outputs": [],
   "source": [
    "# Plot results\n",
    "plt.plot(series, label='Observed')\n",
    "plt.plot(np.arange(train_size, train_size + forecast_steps), forecast, label='Forecast')\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Temperature')\n",
    "plt.title('LSTM Forecast')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close MongoDB connection\n",
    "mongo_client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
